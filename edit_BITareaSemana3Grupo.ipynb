{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonaldGubio92/DeberS1RG/blob/master/edit_BITareaSemana3Grupo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semana 3 Tarea Grupo"
      ],
      "metadata": {
        "id": "hPv7fFYoTZgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Links:\n",
        "DDL Y DML DE LA BASE:\n",
        "https://github.com/ArturoSbr/chinook-postgresql\n",
        "\n",
        "CONSULTAS SQL A REALIZAR SOBRE LA BASE DE DATOS\n",
        "https://m-soro.github.io/Business-Analytics/SQL-for-Data-Analysis/L4-Project-Query-Music-Store/\n",
        "\n",
        "CÃ“DIGOS PARA REALIZAR ETL:\n",
        "https://github.com/tharidlynn/chinook-etl"
      ],
      "metadata": {
        "id": "GOfplF9wUuAA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xw2hM4sbU2zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKpF3bxDTrUi",
        "outputId": "34b7aca6-e8df-44b2-e349-98f43a617b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwGQGLHGTWi_",
        "outputId": "24ee30b3-b19d-491a-c934-94cdeec03bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engine(postgresql+psycopg2://muingxsg:***@peanut.db.elephantsql.com/muingxsg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b00cebd3f4bb>:17: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
            "  df['week'] = df.date.dt.weekofyear\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucessfully created muingxsg data warehouse\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "def create_date_table(start='2000-01-01', end='2020-12-31'):\n",
        "    df = pd.DataFrame({'date': pd.date_range(start, end)})\n",
        "    df['date_id'] = df.index + 1\n",
        "    df['year'] = df.date.dt.year\n",
        "    df['month'] = df.date.dt.month\n",
        "    df['day'] = df.date.dt.day\n",
        "    df['day_name'] = df.date.dt.weekday\n",
        "    df['day_week'] = df.date.dt.dayofweek\n",
        "    df['week'] = df.date.dt.weekofyear\n",
        "    df['quarter'] = df.date.dt.quarter\n",
        "\n",
        "    df = df[['date_id', 'date', 'year', 'month', 'day',\n",
        "             'day_name', 'day_week', 'week', 'quarter']]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_time_table(start='00:00', end='23:59', freq='1min'):\n",
        "\n",
        "    df = pd.DataFrame(pd.date_range(start, end, freq=freq),\n",
        "                      columns=['datetime'])\n",
        "    df['time'] = df.datetime.dt.time\n",
        "    df['hour'] = df.datetime.dt.hour\n",
        "    df['minute'] = df.datetime.dt.minute\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    PG_HOST = os.environ.get('PGHOST')\n",
        "    PG_USERNAME = os.environ.get('PGUSERNAME')\n",
        "    PG_PASSWORD = os.environ.get('PGPASSWORD')\n",
        "    PG_DATABASE = os.environ.get('PGDATABASE')\n",
        "\n",
        "    engine = create_engine(\n",
        "        f'postgresql+psycopg2://{PG_USERNAME}:{PG_PASSWORD}@{PG_HOST}/{PG_DATABASE}')\n",
        "\n",
        "    print(engine)\n",
        "    # create track dimension\n",
        "    media_type_raw = pd.read_sql_table('mediatype', con=engine, schema=\"chinook\")\n",
        "    artist_raw = pd.read_sql_table('artist', con=engine, schema=\"chinook\")\n",
        "    track_raw = pd.read_sql_table('track', con=engine, schema=\"chinook\")\n",
        "    genre_raw = pd.read_sql_table('genre', con=engine, schema=\"chinook\")\n",
        "    album_raw = pd.read_sql_table('album', con=engine, schema=\"chinook\")\n",
        "\n",
        "    media_type_raw.rename(columns={'name': 'media_type'}, inplace=True)\n",
        "    artist_raw.rename(columns={'name': 'artist'}, inplace=True)\n",
        "    genre_raw.rename(columns={'name': 'genre'}, inplace=True)\n",
        "    album_raw.rename(columns={'title': 'album'}, inplace=True)\n",
        "\n",
        "    album = album_raw.merge(artist_raw, on='artistid')\n",
        "    track = track_raw.merge(media_type_raw, on='mediatypeid')\n",
        "    track = track.merge(genre_raw, on='genreid')\n",
        "    track_dim = track.merge(album, on='albumid')\n",
        "\n",
        "    track_dim.drop(['albumid', 'mediatypeid', 'genreid',\n",
        "                   'artistid'], axis=1, inplace=True)\n",
        "    track_dim.sort_values('trackid', inplace=True)\n",
        "\n",
        "    track_dim.to_sql('trackdim', engine, index=False,\n",
        "                     method='multi', schema='dwh', if_exists=\"replace\")\n",
        "\n",
        "    # create customer dimension\n",
        "    customer_dim = pd.read_sql_table('customer', con=engine, schema=\"chinook\")\n",
        "    customer_dim.to_sql('customerdim', engine, index=False,\n",
        "                        method='multi', schema='dwh', if_exists=\"replace\")\n",
        "\n",
        "    # create date dimension\n",
        "    date_dim = create_date_table()\n",
        "    date_dim.to_sql('datedim', engine, index=False,\n",
        "                    method='multi', schema='dwh', if_exists=\"replace\")\n",
        "\n",
        "    # create invoice dimension\n",
        "    invoice_raw = pd.read_sql_table('invoice', con=engine, schema=\"chinook\")\n",
        "    invoice_dim = invoice_raw.drop(['customerid', 'invoicedate'], axis=1)\n",
        "\n",
        "    invoice_dim.to_sql('invoicedim', engine, index=False,\n",
        "                       method='multi', schema='dwh', if_exists=\"replace\")\n",
        "\n",
        "    # create invoice_line fact\n",
        "    invoice_line_raw = pd.read_sql_table('invoiceline', con=engine, schema=\"chinook\")\n",
        "\n",
        "    invoice = pd.merge(invoice_line_raw, invoice_raw[[\n",
        "                       'invoiceid', 'invoicedate', 'customerid']], on='invoiceid', how='left')\n",
        "    invoice = invoice.merge(\n",
        "        date_dim[['date', 'date_id']], left_on='invoicedate', right_on='date')\n",
        "    invoice_fact = invoice[['invoicelineid', 'invoiceid',\n",
        "                            'trackid', 'date_id', 'customerid', 'unitprice', 'quantity']]\n",
        "\n",
        "    invoice_fact.to_sql('invoicefact', engine, index=False,\n",
        "                        method='multi', schema='dwh', if_exists=\"replace\")\n",
        "\n",
        "    print(f'Sucessfully created {PG_DATABASE} data warehouse')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bpVr2ARmTY_v"
      }
    }
  ]
}